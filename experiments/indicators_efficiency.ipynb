{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2093fdb-e9f6-4cc1-97e5-926e23814ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import dirname\n",
    "sys.path.append(dirname(rf'C:\\Projects\\trading'))\n",
    "sys.path.append(dirname(rf'C:\\Projects\\trading\\indicators'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe50a898-ab49-45b4-a1ed-750470b2eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ta.trend import DPOIndicator, adx_pos, adx_neg, cci, macd_diff, EMAIndicator\n",
    "from ta.volume import chaikin_money_flow, acc_dist_index, negative_volume_index\n",
    "from ta.momentum import ROCIndicator, williams_r, stoch_signal, RSIIndicator\n",
    "from ta.volatility import average_true_range\n",
    "import pygad\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78146578-a0d7-467b-822c-b37260909e01",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[\"target_5\"] = 0\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17120\\2768094284.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_df[\"target_3\"] = 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path.join(\"D:\\\\Trading\\\\raw_data\\\\special\", \"SP500.csv\"), parse_dates=True, index_col=\"Date\")\n",
    "data_df = pd.DataFrame(index=df.index)\n",
    "data_df[\"DPO\"] = DPOIndicator(close=df[\"Close\"]).dpo()\n",
    "data_df[\"CMF\"] = chaikin_money_flow(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], volume=df[\"Volume\"])\n",
    "data_df[\"ADI\"] = acc_dist_index(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], volume=df[\"Volume\"])\n",
    "data_df[\"ROC\"] = ROCIndicator(close=df[\"Close\"]).roc()\n",
    "data_df[\"NVI\"] = negative_volume_index(close=df[\"Close\"], volume=df[\"Volume\"])\n",
    "data_df[\"DIU\"] = adx_pos(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "data_df[\"DID\"] = adx_neg(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "data_df[\"WILLR\"] = williams_r(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "data_df[\"CCI\"] = cci(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "data_df[\"STOH\"] = stoch_signal(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "data_df[\"MACD\"] = macd_diff(close=df[\"Close\"])\n",
    "data_df[\"RSI\"] = RSIIndicator(close=df[\"Close\"]).rsi()\n",
    "data_df[\"ATR\"] = average_true_range(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "data_df[\"APO\"] = indicators.apo(close=df[\"Close\"])\n",
    "data_df[\"BIAS\"] = indicators.bias(close=df[\"Close\"])\n",
    "data_df[\"DEMA\"] = indicators.dema(close=df[\"Close\"])\n",
    "data_df[\"HULL\"] = indicators.hull_ma(close=df[\"Close\"])\n",
    "data_df[\"MFM\"] = indicators.mfm(df)\n",
    "data_df[\"RVI\"] = indicators.rvi(df)\n",
    "data_df[\"Supertrend\"] = indicators.supertrend(df)\n",
    "data_df[\"EMA20\"] = EMAIndicator(close=df[\"Close\"], window=20).ema_indicator()\n",
    "data_df[\"EMA50\"] = EMAIndicator(close=df[\"Close\"], window=50).ema_indicator()\n",
    "data_df[\"EMA100\"] = EMAIndicator(close=df[\"Close\"], window=100).ema_indicator()\n",
    "\n",
    "for ind in data_df.columns:\n",
    "    for i in range(1, 5):\n",
    "        data_df[f\"{ind}_{i}\"] = data_df[ind].shift(periods=i)\n",
    "\n",
    "data_df[\"target_5\"] = 0\n",
    "pct_change = df[\"Close\"].pct_change(periods=4).shift(-4)\n",
    "insign_val = 0.02\n",
    "strong_val = 0.04\n",
    "data_df.loc[pct_change >= strong_val, \"target_5\"] = 2\n",
    "data_df.loc[(pct_change < strong_val) & (pct_change >= insign_val), \"target_5\"] = 1\n",
    "data_df.loc[(pct_change > -strong_val) & (pct_change <= -insign_val), \"target_5\"] = -1\n",
    "data_df.loc[pct_change <= -strong_val, \"target_5\"] = -2\n",
    "\n",
    "data_df[\"target_3\"] = 0\n",
    "pct_change = df[\"Close\"].pct_change(periods=2).shift(-2)\n",
    "insign_val = 0.01\n",
    "strong_val = 0.025\n",
    "data_df.loc[pct_change >= strong_val, \"target_3\"] = 2\n",
    "data_df.loc[(pct_change < strong_val) & (pct_change >= insign_val), \"target_3\"] = 1\n",
    "data_df.loc[(pct_change > -strong_val) & (pct_change <= -insign_val), \"target_3\"] = -1\n",
    "data_df.loc[pct_change <= -strong_val, \"target_3\"] = -2\n",
    "\n",
    "data_df.dropna(inplace=True)\n",
    "\n",
    "train_data = data_df[:\"2020-01-01\"]\n",
    "train_X = train_data.drop([\"target_5\", \"target_3\"], axis=1)\n",
    "test_data = data_df[\"2020-01-01\":]\n",
    "test_X = test_data.drop([\"target_5\", \"target_3\"], axis=1)\n",
    "indicators_pull = train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb922956-ca80-455a-8c80-18c9a1611e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    0.670487\n",
       " 1    0.141356\n",
       "-1    0.094556\n",
       "-2    0.047755\n",
       " 2    0.045845\n",
       "Name: target_5, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"target_5\"].value_counts() / test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b71bdc25-f7ae-4917-94b4-1b4388b03d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    0.501433\n",
       " 1    0.221585\n",
       "-1    0.153773\n",
       "-2    0.063992\n",
       " 2    0.059217\n",
       "Name: target_3, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"target_3\"].value_counts() / test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d08cc1b-df5a-4017-832e-1dab83c2e42f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6494746895893028\n",
      "0    0.873926\n",
      "1    0.104107\n",
      "2    0.021968\n",
      "dtype: float64\n",
      "Indicators:\n",
      "Index(['ADI', 'DIU', 'DID', 'DEMA', 'RVI', 'Supertrend', 'EMA100', 'DPO_3',\n",
      "       'DPO_4', 'CMF_1', 'CMF_2', 'CMF_4', 'ADI_1', 'ADI_3', 'ADI_4', 'ROC_1',\n",
      "       'ROC_4', 'NVI_2', 'NVI_3', 'DIU_2', 'DID_1', 'DID_3', 'WILLR_2',\n",
      "       'WILLR_3', 'CCI_1', 'STOH_2', 'STOH_3', 'MACD_3', 'MACD_4', 'BIAS_2',\n",
      "       'DEMA_2', 'DEMA_3', 'HULL_3', 'HULL_4', 'MFM_3', 'Supertrend_1',\n",
      "       'Supertrend_2', 'EMA50_1', 'EMA50_4', 'EMA100_1', 'EMA100_4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=6, class_weight={0: 0.2, 1: 1, -1: 1, 2: 4, -2: 4}, random_state=42)\n",
    "np.random.seed(42)\n",
    "init_pop_p = 0.33\n",
    "initial_pop = np.random.choice([1, 0], p=[init_pop_p, 1-init_pop_p], size=(20, train_X.shape[1]))\n",
    "\n",
    "def fitness_function(ga_inst, solution, solution_idx):\n",
    "    selected_indicators = indicators_pull[solution.astype(bool)]\n",
    "    clf.fit(X=train_X[selected_indicators], y=train_data[\"target_5\"])\n",
    "    predicts = clf.predict(X=test_X[selected_indicators])\n",
    "    acc = accuracy_score(y_true=test_data[\"target_5\"], y_pred=predicts)\n",
    "    return acc\n",
    "\n",
    "\n",
    "ga_instance = pygad.GA(num_generations=300,\n",
    "                       num_parents_mating=2,\n",
    "                       fitness_func=fitness_function,\n",
    "                       initial_population=initial_pop,\n",
    "                       num_genes=train_X.shape[1],\n",
    "                       parent_selection_type=\"rws\",\n",
    "                       keep_elitism=2,\n",
    "                       crossover_type=\"uniform\",\n",
    "                       mutation_type=\"random\",\n",
    "                       mutation_probability=0.02,\n",
    "                       gene_space=[1, 0],\n",
    "                       random_seed=42)\n",
    "ga_instance.run()\n",
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "selected_indicators = indicators_pull[solution.astype(bool)]\n",
    "clf.fit(X=train_X[selected_indicators], y=train_data[\"target_5\"])\n",
    "predicts = clf.predict(X=test_X[selected_indicators])\n",
    "predicts = pd.Series(predicts)\n",
    "print(f\"Accuracy: {solution_fitness}\")\n",
    "print(predicts.value_counts() / predicts.shape[0])\n",
    "print(f\"Indicators:\")\n",
    "print(indicators_pull[solution.astype(bool)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7c0300c-0263-4ab7-9094-1491b6138158",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- APO\n",
      "- APO_4\n",
      "- BIAS\n",
      "- BIAS_1\n",
      "- BIAS_4\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- ADI\n",
      "- ADI_1\n",
      "- ADI_3\n",
      "- CCI_1\n",
      "- CMF_4\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 43 features, but RandomForestClassifier is expecting 41 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m selected_indicators \u001b[38;5;241m=\u001b[39m indicators_pull[solution\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)]\n\u001b[0;32m     29\u001b[0m clf2\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mtrain_X[selected_indicators], y\u001b[38;5;241m=\u001b[39mtrain_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_3\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 30\u001b[0m predicts \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_X\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_indicators\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m predicts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(predicts)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolution_fitness\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:808\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 808\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:850\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    848\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    853\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 579\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 43 features, but RandomForestClassifier is expecting 41 features as input."
     ]
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(max_depth=6, class_weight={0: 0.2, 1: 1, -1: 1, 2: 4, -2: 4}, random_state=42)\n",
    "np.random.seed(42)\n",
    "init_pop_p = 0.33\n",
    "initial_pop = np.random.choice([1, 0], p=[init_pop_p, 1-init_pop_p], size=(20, train_X.shape[1]))\n",
    "\n",
    "def fitness_function2(ga_inst, solution, solution_idx):\n",
    "    selected_indicators = indicators_pull[solution.astype(bool)]\n",
    "    clf2.fit(X=train_X[selected_indicators], y=train_data[\"target_3\"])\n",
    "    predicts = clf2.predict(X=test_X[selected_indicators])\n",
    "    acc = accuracy_score(y_true=test_data[\"target_3\"], y_pred=predicts)\n",
    "    return acc\n",
    "\n",
    "\n",
    "ga_instance2 = pygad.GA(num_generations=200,\n",
    "                       num_parents_mating=2,\n",
    "                       fitness_func=fitness_function2,\n",
    "                       initial_population=initial_pop,\n",
    "                       num_genes=train_X.shape[1],\n",
    "                       parent_selection_type=\"rws\",\n",
    "                       keep_elitism=2,\n",
    "                       crossover_type=\"uniform\",\n",
    "                       mutation_type=\"random\",\n",
    "                       mutation_probability=0.02,\n",
    "                       gene_space=[1, 0],\n",
    "                       random_seed=42)\n",
    "ga_instance2.run()\n",
    "solution, solution_fitness, solution_idx = ga_instance2.best_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e598e0a-b4be-46e6-85d5-e0667c0ae949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4785100286532951\n",
      " 0    0.594078\n",
      " 1    0.191022\n",
      "-2    0.135626\n",
      " 2    0.068768\n",
      "-1    0.010506\n",
      "dtype: float64\n",
      "Indicators:\n",
      "Index(['ROC', 'DIU', 'STOH', 'APO', 'BIAS', 'HULL', 'Supertrend', 'EMA50',\n",
      "       'EMA100', 'DPO_1', 'DPO_2', 'DPO_4', 'CMF_1', 'CMF_2', 'ADI_4', 'ROC_4',\n",
      "       'NVI_2', 'NVI_3', 'DIU_2', 'DIU_3', 'DID_4', 'WILLR_2', 'WILLR_3',\n",
      "       'CCI_3', 'STOH_3', 'MACD_1', 'MACD_4', 'RSI_2', 'APO_4', 'BIAS_1',\n",
      "       'BIAS_2', 'BIAS_4', 'DEMA_1', 'HULL_2', 'HULL_3', 'MFM_3', 'RVI_4',\n",
      "       'Supertrend_2', 'Supertrend_3', 'EMA20_2', 'EMA20_4', 'EMA50_3',\n",
      "       'EMA100_4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "selected_indicators = indicators_pull[solution.astype(bool)]\n",
    "clf2.fit(X=train_X[selected_indicators], y=train_data[\"target_3\"])\n",
    "predicts = clf2.predict(X=test_X[selected_indicators])\n",
    "predicts = pd.Series(predicts)\n",
    "print(f\"Accuracy: {solution_fitness}\")\n",
    "print(predicts.value_counts() / predicts.shape[0])\n",
    "print(f\"Indicators:\")\n",
    "print(indicators_pull[solution.astype(bool)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80201472-7c58-4fba-b916-f9e0bf53be2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
